# -*- coding: utf-8 -*-
"""App 2_24A1HP001_Deepthi P.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YFt0CfMgGpzonLYbUYCqk67MmG5Uwktz
"""

import streamlit as st
import pypdf
import nltk
import re
import matplotlib.pyplot as plt
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from wordcloud import WordCloud

# Download NLTK resources
nltk.download("punkt")
nltk.download("stopwords")

# Title
st.title("üîç PDF Paragraph Extractor + Word Cloud Generator")
st.write("Upload a PDF and enter multiple keywords to extract relevant paragraphs and generate a word cloud.")

# Upload PDF
uploaded_file = st.file_uploader("Upload PDF", type="pdf")

# Keyword input
keywords_input = st.text_input("Enter keywords (comma-separated)", "")

# Process only if both PDF and keywords provided
if uploaded_file and keywords_input.strip():

    # Parse keywords
    keywords = [k.strip().lower() for k in keywords_input.split(",") if k.strip()]
    st.write(f"### üîé Searching for paragraphs containing ALL keywords: {keywords}")

    # Read PDF
    reader = pypdf.PdfReader(uploaded_file)
    full_text = ""
    for page in reader.pages:
        full_text += page.extract_text() or ""

    if not full_text.strip():
        st.error("No extractable text found in the PDF.")
        st.stop()

    # Split into paragraphs
    paragraphs = [p.strip() for p in full_text.split("\n\n") if len(p.strip()) > 20]

    # Find paragraphs containing ALL keywords
    matched_paragraphs = []
    for para in paragraphs:
        low_para = para.lower()
        if all(k in low_para for k in keywords):
            matched_paragraphs.append(para)

    # Display matched paragraphs
    if matched_paragraphs:
        st.subheader("üìÑ Extracted Paragraphs Containing All Keywords")
        for p in matched_paragraphs:
            st.write("- " + p)
    else:
        st.warning("No paragraphs matched all keywords.")
        st.stop()

    # Combine text for word cloud
    combined_text = " ".join(matched_paragraphs)

    # Preprocess text
    clean = re.sub(r"[^a-zA-Z\s]", " ", combined_text.lower())
    clean = re.sub(r"\s+", " ", clean)

    # Tokenize
    tokens = word_tokenize(clean)

    # Remove stopwords
    stop_words = set(stopwords.words("english"))
    words = [w for w in tokens if w not in stop_words and len(w) > 2]

    if len(words) == 0:
        st.error("No valid words found to generate a word cloud.")
        st.stop()

    # Generate word cloud
    wordcloud = WordCloud(
        width=1000,
        height=500,
        background_color="white",
        stopwords=stop_words,
        colormap="viridis",
        max_words=200,
    ).generate(" ".join(words))

    # Display word cloud
    st.subheader("‚òÅÔ∏è Word Cloud of Extracted Paragraphs")
    plt.figure(figsize=(12, 6))
    plt.imshow(wordcloud, interpolation="bilinear")
    plt.axis("off")
    st.pyplot(plt)

else:
    st.info("Please upload a PDF and enter keywords to begin.")

